{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import transformers\n",
    "import string \n",
    "from spacy.lang.en import English\n",
    "from nltk.corpus import stopwords as stopwords\n",
    "from tqdm import notebook\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r'C:\\Users\\Andrey\\Desktop\\Soft balls\\Yandex\\WorkBooks\\toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.898321\n",
       "1    0.101679\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['toxic'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Классы не сбалансированны."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrey\\Anaconda3\\lib\\site-packages\\tqdm\\std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas(desc=\"my bar!\") # для отображения временных затрат на работу ячеек"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для подготовки данных воспользуемся библиотекой SPACY, произведем токенизацию посредствам данной библиотек."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\") #загрузим модель spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import string \n",
    "from spacy.lang.en import English\n",
    "from nltk.corpus import stopwords as stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations=string.punctuation\n",
    "punctuations+=('•')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~•'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "выберем стоп-слова из библиотек spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_spacy=STOP_WORDS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(row):\n",
    "    tokens=nlp(row) # произведем токенизацию строки\n",
    "    tokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in tokens ] #приведем все слова к нижнему регистру \n",
    "    tokens = [ word for word in tokens if word not in stop_words_spacy and word not in punctuations ] # удалим знаки препинания\n",
    "    tokens=' '.join(tokens) # Объединим списки в str\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "my bar!: 100%|█████████████████████████████████████████████████████████████████| 159571/159571 [41:16<00:00, 64.42it/s]\n"
     ]
    }
   ],
   "source": [
    "lemma=df['text'].progress_apply(tokenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemma']=lemma.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         explanation edit username hardcore metallica f...\n",
       "1         d'aww match background colour seemingly stick ...\n",
       "2         hey man try edit war guy constantly remove rel...\n",
       "3         real suggestion improvement wonder section sta...\n",
       "4                             sir hero chance remember page\n",
       "                                ...                        \n",
       "159566    second time asking view completely contradict ...\n",
       "159567        ashamed horrible thing talk page 128.61.19.93\n",
       "159568    spitzer umm s actual article prostitution ring...\n",
       "159569        look like actually speedy version delete look\n",
       "159570    ... think understand come idea bad right away ...\n",
       "Name: lemma, Length: 159571, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lemma']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- мы изучили данные\n",
    "- провели лемматизацию наших данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение SPACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Раздели выборки на обучающую и тестовую. На обучающей проведем кросс-валидацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['lemma']\n",
    "y = df['toxic'] \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся pipeline для того, что бы провести кросс валидацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_calculation(X,y,balanced=True):\n",
    "    results={}\n",
    "    for model,model_name in zip((LogisticRegression,LGBMClassifier,RandomForestClassifier),\n",
    "                                ('LogisticRegression','LGBMClassifier','RandomForestClassifier')):\n",
    "        if balanced==True:\n",
    "            classifier =model(class_weight='balanced')\n",
    "        elif balanced==False:\n",
    "            classifier =model()\n",
    "        clf = make_pipeline(TfidfVectorizer(), classifier)\n",
    "        scores = cross_val_score(clf, X, y, scoring='f1', cv=5)\n",
    "        results[model_name]=np.mean(scores)\n",
    "        print(results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LogisticRegression': 0.7497422751382493}\n",
      "{'LogisticRegression': 0.7497422751382493, 'LGBMClassifier': 0.7352967725263264}\n",
      "{'LogisticRegression': 0.7497422751382493, 'LGBMClassifier': 0.7352967725263264, 'RandomForestClassifier': 0.6469286160449809}\n"
     ]
    }
   ],
   "source": [
    "tf_idf_metod=result_calculation(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LogisticRegression': 0.7497422751382493,\n",
       " 'LGBMClassifier': 0.7352967725263264,\n",
       " 'RandomForestClassifier': 0.6469286160449809}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_metod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <th>RandomForestClassifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.749742</td>\n",
       "      <td>0.735297</td>\n",
       "      <td>0.646929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    LogisticRegression  LGBMClassifier  RandomForestClassifier\n",
       "F1            0.749742        0.735297                0.646929"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tf_idf_metod,index=['F1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы провели кросс-валидацию, по ее рузльтатам лушей моделью оказалась LogisticRegression.   \n",
    "Ее рузультат 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier =LogisticRegression(class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidfvectorizer',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token...ern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = make_pipeline(TfidfVectorizer(), classifier)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.942889371657754\n",
      "Logistic Regression Precision: 0.6741224489795918\n",
      "Logistic Regression Recall: 0.8483665502362852\n",
      "Logistic Regression F1: 0.7512736535662299\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression Accuracy:\",metrics.accuracy_score(y_test, predicted))\n",
    "print(\"Logistic Regression Precision:\",metrics.precision_score(y_test, predicted))\n",
    "print(\"Logistic Regression Recall:\",metrics.recall_score(y_test, predicted))\n",
    "print(\"Logistic Regression F1:\",metrics.f1_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы провели тестирование подобранной модели LogisticRegression на тестовой выборке.  \n",
    "Результат превысил целевой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применем облегченную версию BERT -DistilBERT уже предобученную."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = transformers.DistilBertModel.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BERT(data):\n",
    "    # из полученных данных на этапе токенизации выделим тензоры ids и attention mask\n",
    "    attention_mask=[]\n",
    "    padded=[]\n",
    "    for i in data:\n",
    "        padded.append(i['input_ids'])\n",
    "        attention_mask.append(i['attention_mask'])\n",
    "    # выберем батчи равные 50 для рассчетов эмбендингов\n",
    "    batch_size =50\n",
    "    embeddings = []\n",
    "    for i in notebook.tqdm(range(np.array(data).shape[0] // batch_size)):\n",
    "            batch=torch.cat(padded[batch_size*i:batch_size*(i+1)], dim=0) # обединим списки тензоров в список тензоров ids\n",
    "            attention_mask_batch=torch.cat(attention_mask[batch_size*i:batch_size*(i+1)], dim=0) # обединим списки тензоров в список тензоров attention masks\n",
    "\n",
    "\n",
    "            with torch.no_grad():\n",
    "                batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "\n",
    "            embeddings.append(batch_embeddings[0][:,0,:].numpy())\n",
    "    return np.concatenate(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(features, target, fraction):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "    features_downsampled = pd.concat([features_zeros.sample(frac=fraction, random_state=12345)] + [features_ones])\n",
    "    target_downsampled = pd.concat([target_zeros.sample(frac=fraction, random_state=12345)] + [target_ones])\n",
    "    features_downsampled, target_downsampled = shuffle(\n",
    "    features_downsampled, target_downsampled, random_state=12345)\n",
    "    return features_downsampled, target_downsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Т.к. наши классы несбалансированны, то применем метод даунсемплинг для его балансировки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, targets= downsample(df['text'],df['toxic'],0.11) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.507142\n",
       "0    0.492858\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "my bar!: 100%|██████████████████████████████████████████████████████████████████| 31993/31993 [00:41<00:00, 776.48it/s]\n"
     ]
    }
   ],
   "source": [
    "features['tokenized'] = features.progress_apply(\n",
    "    lambda x: tokenizer.encode_plus(\n",
    "  x,\n",
    "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
    "      return_token_type_ids=False,\n",
    "      pad_to_max_length=True,\n",
    "      return_attention_mask=True,\n",
    "      max_length=50, \n",
    "        # данное число выбрано для ускорения обучения модели, целом если после токенизации считать 0.75 квантиль равен 100. \n",
    "        # Правильнее применить его, но тогда неполучается все рассчиать \n",
    "      return_tensors='pt',truncation=True\n",
    "        # Return PyTorch tensors\n",
    "))\n",
    "# на выходе получаем два словаря с ids тензорами и attention mask тензорами. \n",
    "# В дальнейшем разделим их на списки и будем объединят под каждую батчу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим уже токенизированную выборку на тестовую и обучающую"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features\n",
    "y = targets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.503237\n",
       "0    0.496763\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы провести кросс-валидацию KFold сбросим индексы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=y_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf=KFold(n_splits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7465  7466  7467 ... 22392 22393 22394]\n",
      "[    0     1     2 ... 22392 22393 22394]\n",
      "[    0     1     2 ... 14927 14928 14929]\n"
     ]
    }
   ],
   "source": [
    "for train_index,test_index in kf.split(X_train):\n",
    "    print(train_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При проведении кросс-валидации будем использовать только LogisticRegression, она лучше всех показала себя в предыдущей CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8fc6ca9e9f44e36862da80805df1b64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=298.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b713f2d6a8cb4c92a8a2e9f7092acc55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=149.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Accuracy: 0.8794630872483221\n",
      "Logistic Regression Precision: 0.8919067215363512\n",
      "Logistic Regression Recall: 0.8657789613848202\n",
      "Logistic Regression F1: 0.8786486486486487\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrey\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77aee20f86ac466fa7b23d09a61404cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=298.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "166646cab2be401d961f995ef1322644",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=149.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Accuracy: 0.881744966442953\n",
      "Logistic Regression Precision: 0.8868852459016393\n",
      "Logistic Regression Recall: 0.8742256935092917\n",
      "Logistic Regression F1: 0.8805099688050997\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrey\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5bd33489b03440e8ed2fba824a2c5fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=298.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1bc1adb16d44e2ba1ab400e5a9df68e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=149.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Accuracy: 0.8769127516778523\n",
      "Logistic Regression Precision: 0.8859530870854678\n",
      "Logistic Regression Recall: 0.8693121693121693\n",
      "Logistic Regression F1: 0.8775537454933904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrey\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "for train_index,test_index in kf.split(X_train):\n",
    "    results=[]\n",
    "    X_train_cv=X_train[train_index]\n",
    "    X_test_cv=X_train[test_index]\n",
    "    y_train_cv=y_train[train_index]\n",
    "    y_test_cv=y_train[test_index]\n",
    "    print()\n",
    "    train_embeddings=BERT(X_train_cv)\n",
    "    test_embeddings=BERT(X_test_cv)\n",
    "    model_lr=LogisticRegression()\n",
    "    model_lr.fit(train_embeddings,y_train_cv.iloc[:len(train_embeddings)])\n",
    "    predicted=model_lr.predict(test_embeddings)\n",
    "    print(\"Logistic Regression Accuracy:\",metrics.accuracy_score(y_test_cv.iloc[:len(test_embeddings)], predicted))\n",
    "    print(\"Logistic Regression Precision:\",metrics.precision_score(y_test_cv.iloc[:len(test_embeddings)], predicted))\n",
    "    print(\"Logistic Regression Recall:\",metrics.recall_score(y_test_cv.iloc[:len(test_embeddings)], predicted))\n",
    "    print(\"Logistic Regression F1:\",metrics.f1_score(y_test_cv.iloc[:len(test_embeddings)], predicted))\n",
    "    results+=metrics.f1_score(y_test_cv.iloc[:len(test_embeddings)], predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- мы выборали модель BERT, загрузили ее и токенизатор.\n",
    "- токенизировали данные, ращделили выборку на тестовую и обучающую\n",
    "- на обучающей выборке мы провели кросс-валидацию модели LogisticRegression\n",
    "- результат F1 меры оказался равен 0.88"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af3bbf6f578e4bad93e8bc18a742a8df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=191.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_test_emb=BERT(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72211a7ed0ff4d83b3fc89fd3897fbd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=447.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_emb=BERT(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrey\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr.fit(X_train_emb,y_train.iloc[:len(X_train_emb)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=model_lr.predict(X_test_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression F1: 0.884928402183991\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression F1:\",metrics.f1_score(y_test.iloc[:len(X_test_emb)], prediction))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- мы протестировали нашу модель\n",
    "- результат оказался 0.88, что выше целевого 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Мы изучили данные\n",
    "1. Ипользование SPACY\n",
    "    - Провели лемматизацию\n",
    "    - Провели кросс-валидацию\n",
    "    - Лучшей моделью по ее резльтатам оказалась LogisticRegression с результатом 0.75\n",
    "    - Провели тестирование на тестовой выборке, результат составил 0.75\n",
    "2. Использование BERT\n",
    "    - мы выборали модель BERT, загрузили ее и токенизатор.\n",
    "    - токенизировали данные, раpделили выборку на тестовую и обучающую\n",
    "    - на обучающей выборке мы провели кросс-валидацию модели LogisticRegression\n",
    "    - результат F1 меры оказался равен 0.88\n",
    "    - результат F! меры на тестовой выборке оказался равен 0.88\n",
    "____\n",
    "Модель BERT показала лучшие результаты по сравнению с SPACY и tf-idf методом.  \n",
    "Но трудозатраты и время обучения у первой сильно выше, хотя в обоих слуаях мы смогли достичь требуемое качество целевой метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
